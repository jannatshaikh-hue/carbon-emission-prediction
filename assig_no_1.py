# -*- coding: utf-8 -*-
"""Assig no 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F3wm6T7NA4o7Bh_gdQLOJB-iyIBR8Flr

Step 1: Import Libraries
"""

# Data handling
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Model saving
import joblib

# Plot style
sns.set(style="whitegrid")

from google.colab import drive
drive.mount('/content/drive')

"""ðŸ”¹ Step 2: Load the Dataset"""

import pandas as pd

# Load dataset
df = pd.read_csv("edunet_indivisual_daily_carbon_usage.csv")

# Display first 5 rows
df.head()

"""ðŸ”¹ Step 3: Data Exploration

ðŸ“Œ Shape of the dataset
"""

df.shape

"""ðŸ“Œ Dataset information"""

df.info()

"""ðŸ“Œ Statistical summary"""

df.describe()

"""ðŸ“Œ Check for missing values"""

df.isnull().sum()

"""ðŸ”¹ For numerical columns (use mean)"""

df.fillna(df.mean(numeric_only=True), inplace=True)

"""ðŸ”¹ Step 4: Data Cleaning"""

# Handle missing values (if any)
df = df.dropna()

# Remove duplicate rows
df = df.drop_duplicates()

# Verify cleaning
df.isnull().sum(), df.duplicated().sum()

"""ðŸ”¹ Step 5: Exploratory Data Analysis (EDA)

ðŸ“Œ Correlation Matrix
"""

correlation_matrix = df.corr(numeric_only=True)
correlation_matrix

"""ðŸ“Œ Strongest relationships with target variable"""

correlation_matrix['total_daily_co2_kg'].sort_values(ascending=False)

"""ðŸ”¹ Step 6: Data Visualization

ðŸ“Œ Heatmap of Correlations
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

"""ðŸ“Œ Scatter Plot: Distance vs COâ‚‚ Emissions"""

plt.figure(figsize=(5, 5))
sns.scatterplot(x='distance_km', y='total_daily_co2_kg', data=df)
plt.title("Distance Travelled vs Daily COâ‚‚ Emissions")
plt.show()

"""ðŸ“Œ Box Plot: Transport Mode vs COâ‚‚ Emissions"""

plt.figure(figsize=(5, 5))
sns.boxplot(x='transport_mode', y='total_daily_co2_kg', data=df)
plt.title("COâ‚‚ Emissions by Transport Mode")
plt.xticks(rotation=45)
plt.show()

"""ðŸ”¹ 1. Distribution Plot (Histogram) of COâ‚‚ Emissions"""

plt.figure(figsize=(5,5))
sns.histplot(df['total_daily_co2_kg'], bins=30, kde=True)
plt.title("Distribution of Total Daily COâ‚‚ Emissions")
plt.xlabel("COâ‚‚ Emissions (kg)")
plt.ylabel("Frequency")
plt.show()

"""ðŸ”¹ 6. Actual vs Predicted Plot (Model Visualization)"""

plt.figure(figsize=(5,5))
sns.scatterplot(x=y_test, y=y_pred)
plt.xlabel("Actual COâ‚‚ Emissions")
plt.ylabel("Predicted COâ‚‚ Emissions")
plt.title("Actual vs Predicted COâ‚‚ Emissions")
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         color='red', linestyle='--')
plt.show()

"""ðŸ”¹ 4. Bar Plot (Average COâ‚‚ by Transport Mode)"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(5,5))
sns.barplot(
    x='transport_mode',
    y='total_daily_co2_kg',
    data=df,
    estimator=np.mean
)
plt.title("Average COâ‚‚ Emissions by Transport Mode")
plt.xticks(rotation=45)
plt.show()

"""ðŸ”¹ Step 7: Data Preprocessing

ðŸ“Œ One-Hot Encoding
"""

df_encoded = pd.get_dummies(df, columns=['transport_mode'], drop_first=True)

"""ðŸ“Œ Feature Selection"""

X = df_encoded.drop(['total_daily_co2_kg', 'date', 'role', 'program'], axis=1)
y = df_encoded['total_daily_co2_kg']

"""ðŸ“Œ Train-Test Split"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""ðŸ”¹ Step 8: Model Selection and Training"""

from sklearn.linear_model import LinearRegression
import pandas as pd

# Initialize model
model = LinearRegression()

# Train model
model.fit(X_train, y_train)

# Model parameters
print("Intercept:", model.intercept_)
print("Coefficients:")
pd.Series(model.coef_, index=X.columns)

"""ðŸ”¹ Step 9: Model Evaluation

ðŸ“Œ Predictions
"""

y_pred = model.predict(X_test)

"""ðŸ“Œ Performance Metrics"""

from sklearn.metrics import mean_squared_error, r2_score

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared Score:", r2)

"""ðŸ“Œ Residual Plot"""

residuals = y_test - y_pred

plt.figure(figsize=(5, 5))
sns.scatterplot(x=y_pred, y=residuals)
plt.axhline(0, color='red', linestyle='--')
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()

"""ðŸ”¹ Step 10: Model Saving"""

import joblib

# Save the trained model
joblib.dump(model, "carbon_model.pkl")

print("Model saved successfully as carbon_model.pkl")